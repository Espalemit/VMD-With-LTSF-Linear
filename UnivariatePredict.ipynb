{"cells":[{"cell_type":"code","execution_count":null,"id":"0wfTwbhYYB3_","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34112,"status":"ok","timestamp":1721974594433,"user":{"displayName":"20-Hafizh Raihan Kurnia Putra","userId":"07590719626580236638"},"user_tz":-420},"id":"0wfTwbhYYB3_","outputId":"40e2c6f9-6ca7-4682-c899-db78efa79be5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"]},{"cell_type":"code","execution_count":null,"id":"xhw5uoN-YEf4","metadata":{"id":"xhw5uoN-YEf4"},"outputs":[],"source":["import sys\n","sys.path.append('/content/gdrive/My Drive/Skripsi VMD LSTM Udara/Progress')"]},{"cell_type":"code","execution_count":null,"id":"7ae2aca3-15ab-4b8f-92f7-80f018dfcd68","metadata":{"id":"7ae2aca3-15ab-4b8f-92f7-80f018dfcd68","colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"status":"error","timestamp":1721974604196,"user_tz":-420,"elapsed":9765,"user":{"displayName":"20-Hafizh Raihan Kurnia Putra","userId":"07590719626580236638"}},"outputId":"a76de6ea-e8fc-4851-c325-6a6d57f9e88e"},"outputs":[{"output_type":"error","ename":"TabError","evalue":"inconsistent use of tabs and spaces in indentation (LmylFun.py, line 49)","traceback":["Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n","  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3553\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n","\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-fa3cec29ad05>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0;36m, in \u001b[0;35m<cell line: 13>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from Modules.LmylFun import LSTM, BLSTM, SimpRNN, NLin, DLin, Lin\u001b[0m\n","\u001b[0;36m  File \u001b[0;32m\"/content/gdrive/My Drive/Skripsi VMD LSTM Udara/Progress/Modules/LmylFun.py\"\u001b[0;36m, line \u001b[0;32m49\u001b[0m\n\u001b[0;31m    return out\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib as plt\n","from torch.utils.data import Dataset, DataLoader\n","from copy import deepcopy as dc\n","import math\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import StandardScaler\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from Modules.LmylFun import LSTM, BLSTM, SimpRNN, NLin, DLin, Lin\n","from Modules.LmylFun import VMD\n","from Modules.LmylFun import PostVMD"]},{"cell_type":"code","execution_count":null,"id":"51267aba-51e0-452d-8ad3-98201ebfb8ca","metadata":{"id":"51267aba-51e0-452d-8ad3-98201ebfb8ca"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","n_steps = 6\n","scaler = StandardScaler()\n","\n","# List Of Training And Test Data Set\n","trn_li = []\n","tst_li = []\n","\n","# Univariate Data List\n","uni_list = ['banjarbaru_pr',\n","            'batam_pr',\n","            'jakarta_pr',\n","            'jakarta-selatan_pr',\n","            'jambi_pr',\n","            'malang_pr',\n","            'medan_pr',\n","            'samarinda_pr',\n","            'semarang_pr']\n","\n","for fileName in uni_list:\n","    df = pd.read_csv(\"/content/gdrive/My Drive/Skripsi VMD LSTM Udara/DATASET/Pre-Ready Data/Univariate/\"+fileName+\".csv\")\n","    df = df[['Unnamed: 0','pm25']]\n","    df.drop(df.tail(1).index,inplace=True)\n","\n","    df_tr = df[[:int(len(df)*(90/100))]]\n","    df_tr = pd.DataFrame(scaler.fit_transform(df_tr[['pm25']]), columns=['pm25'])\n","\n","    df_ts = df[[-(int(len(df)*(10/100))):]]\n","    df_ts = pd.DataFrame(scaler.fit_transform(df_ts[['pm25']]), columns=['pm25'])\n","\n","    trn_li.append(df_tr)\n","    tst_li.append(df_ts)\n","\n","# M4 WEEKLY TRAIN DATA\n","df_tr = pd.read_csv(\"/content/gdrive/My Drive/Skripsi VMD LSTM Udara/DATASET/Pre-Ready Data/Multivariate/m4-week-train.csv\")\n","df_tr['V1'] = pd.to_datetime(df_tr['V1'], format='%Y-%m-%d')\n","df_tr = df_tr[5:]\n","df_tr = df_tr.set_index('V1')\n","df_tr = pd.DataFrame(scaler.fit_transform(df_tr[['V2']]), columns=['V2'])\n","\n","trn_li.append(df_tr)\n","\n","# M4 WEEKLY TEST DATA\n","df_ts = pd.read_csv(\"/content/gdrive/My Drive/Skripsi VMD LSTM Udara/DATASET/Pre-Ready Data/Multivariate/m4-week-test.csv\")\n","df_ts['V1'] = pd.to_datetime(df_ts['V1'], format='%Y-%m-%d')\n","df_ts = df_ts[:-5]\n","df_ts = df_ts.set_index('V1')\n","df_ts = pd.DataFrame(scaler.fit_transform(df_ts[['V2']]), columns=['V2'])\n","\n","tst_li.append(df_ts)\n","\n","# SINGAPORE PM10 DATA\n","df = pd.read_csv(\"/content/gdrive/My Drive/Skripsi VMD LSTM Udara/DATASET/Pre-Ready Data/Multivariate/central_singapore.csv\")\n","df.drop(df.tail(1).index,inplace=True)\n","df_tr = df[[:int(len(df)*(90/100))]]\n","df_tr = pd.DataFrame(scaler.fit_transform(df_tr[['pm10']]), columns=['pm10'])\n","\n","df_ts = df[[-(int(len(df)*(10/100))):]]\n","df_ts = pd.DataFrame(scaler.fit_transform(df_ts[['pm10']]), columns=['pm10'])\n","trn_li.append(df_tr)\n","tst_li.append(df_ts)\n","\n","# WIND TURBINE ACTIVEPOWER DATA\n","df = pd.read_csv(\"/content/gdrive/My Drive/Skripsi VMD LSTM Udara/DATASET/Pre-Ready Data/Multivariate/Turbine_neo.csv\")\n","df = df[[:-10]]\n","df_tr = df[[:int(len(df)*(80/100))]]\n","df_tr = pd.DataFrame(scaler.fit_transform(df_tr[['LV ActivePower (kW)']]), columns=['LV ActivePower (kW)'])\n","\n","df_ts = df[[-(int(len(df)*(20/100))):]]\n","df_ts = pd.DataFrame(scaler.fit_transform(df_ts[['LV ActivePower (kW)']]), columns=['LV ActivePower (kW)'])\n","trn_li.append(df_tr)\n","tst_li.append(df_ts)\n","\n","# ETTm2 HUFL DATA\n","df = pd.read_csv(\"/content/gdrive/My Drive/Skripsi VMD LSTM Udara/DATASET/Pre-Ready Data/Multivariate/ETTm2_neo.csv\")\n","df = df[[[:-59690]]\n","df_tr = df[[:int(len(df)*(80/100))]]\n","df_tr = pd.DataFrame(scaler.fit_transform(df_tr[['HUFL']]), columns=['HUFL'])\n","\n","df_ts = df[[-(int(len(df)*(20/100))):]]\n","df_ts = pd.DataFrame(scaler.fit_transform(df_ts[['HUFL']]), columns=['HUFL'])\n","trn_li.append(df_tr)\n","tst_li.append(df_ts)\n","\n","# The Train & Test List Data by Index\n","# 1. Banjarbaru (PM25)\n","# 2. Batam (PM25)\n","# 3. Jakarta (PM25)\n","# 4. Jakarta-Selatan (PM25)\n","# 5. Jambi (PM25)\n","# 6. Malang (PM25)\n","# 7. Medan (PM25)\n","# 8. Samarinda (PM25)\n","# 9. Semarang (PM25)\n","# 10. M4 Weekly (V1)\n","# 11. Singapore (PM10)\n","# 12. WindTurbine (LV ActivePower (kW))\n","# 13. ETTm2 (HUFL)"]},{"cell_type":"code","source":["def processResult(out, y_f, y_forsum, sums):\n","    for i, data in enumerate(out[0]):\n","        sums.append([])\n","        for a, dataA in enumerate(out):\n","            sums[i].append([])\n","\n","    for i, data in enumerate(y_f[0]):\n","        y_forsum.append([])\n","        for a, dataA in enumerate(y_f):\n","            y_forsum[i].append([])\n","\n","    #print(sum)\n","    for i, data in enumerate(out[0]):\n","        for a, dataA in enumerate(out):\n","            sums[i][a] = np.array(out[a][i].cpu())\n","        sums[i] = np.array(sums[i])\n","        sums[i] = sums[i].sum(axis=0)\n","\n","    for i, data in enumerate(y_f[0]):\n","        for a, dataA in enumerate(y_f):\n","            y_forsum[i][a] = y_f[a][i].tolist()\n","        #print(y_forsum[i])\n","        y_forsum[i] = np.array(y_forsum[i])\n","        y_forsum[i] = y_forsum[i].sum(axis=0)\n","\n","    for i, d in enumerate(sums):\n","        sums[i] = d.tolist()\n","        y_forsum[i] = y_forsum[i].tolist()\n","\n","    out1 = []\n","    y1 = []\n","    #print(len(sum))\n","    #print(len(y_fsm))\n","    for i, d in enumerate(sums[0]):\n","        for o, g in enumerate(sums[0][i]):\n","            out1.append(g)\n","            y1.append(y_forsum[i][o])\n","\n","    #print(sums, '\\n')\n","    #print(y_forsum, '\\n')\n","    #print(len(y1), '\\n', y1, '\\n\\n', len(out1), '\\n', out1)\n","    rmse_final = math.sqrt(mean_squared_error(y1, out1))\n","    return rmse_final"],"metadata":{"id":"Ybi29crnl0-u"},"id":"Ybi29crnl0-u","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"39854c92-5811-4e98-b0e9-69b29f664e32","metadata":{"id":"39854c92-5811-4e98-b0e9-69b29f664e32"},"outputs":[],"source":["def preparing(df, step, textCol):\n","  df = dc(df)\n","\n","  for i in range(1, step + 1):\n","    df[f'pm10(t-{i})'] = df[textCol].shift(i)\n","\n","  return df\n","\n","# Class For New DataType\n","class TimeData(Dataset):\n","  def __init__(self, X, y):\n","    self.X = X\n","    self.y = y\n","\n","  def __len__(self):\n","    return len(self.X)\n","\n","  def __getitem__(self, i):\n","    return self.X[i], self.y[i]\n","\n","# For Model Training And Evaluation\n","def validate_one_epoch(model, test, lossf_def, show_test):\n","  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","  model.train(False)\n","  running_loss = 0.0\n","\n","  out_nov = []\n","  y_fsum = []\n","\n","  for batch_index, batch in enumerate(test):\n","    x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n","\n","    with torch.no_grad():\n","      output = model(x_batch)\n","      loss = torch.sqrt(lossf_def(output, y_batch))\n","      out_nov.append(output)\n","      y_fsum.append(y_batch)\n","      #print(x_batch)\n","      running_loss += loss.item()\n","\n","  avg_loss_across_batches = running_loss / len(test)\n","\n","  if show_test:\n","    print('RMSE Loss: ',avg_loss_across_batches)\n","    print('---------------------------------------')\n","\n","  return out_nov, avg_loss_across_batches, y_fsum\n","\n","def train_one_epoch(model, train, optimz, lossf_def, epoch, max_norm, linear):\n","  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","  torch.autograd.set_detect_anomaly(True)\n","  model.train(True)\n","  running_loss = 0.0\n","\n","  for batch_index, batch in enumerate(train):\n","    x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n","\n","    output = model(x_batch)\n","\n","    if output.isnan().any().item() or y_batch.isnan().any().item():\n","        print(output,' Those are the outputs, and these are the inputs ', x_batch)\n","        return True\n","\n","    if linear:\n","        loss = torch.sqrt(lossf_def(output, y_batch))+0.5*torch.norm(torch.cat([torch.randn(n_steps, 1).view(-1)]), 1)\n","    else:\n","        loss = torch.sqrt(lossf_def(output, y_batch))\n","    running_loss += loss.item()\n","\n","    optimz.zero_grad()\n","    loss.backward()\n","\n","    #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n","\n","    optimz.step()\n","\n","  return False\n","\n","def train_test_v1(model, train, test, lrn=0.001, iterasi=50, loss=nn.MSELoss(), max_norm=1, show_test=False, linear=False):\n","  optimz = torch.optim.Adam(model.parameters(), lr=lrn)\n","  skipTrain = False\n","\n","  for epoch in range(iterasi):\n","    if skipTrain == False:\n","        skipTrain = train_one_epoch(model, train, optimz, loss, epoch, max_norm, linear)\n","    out, rmse, y_fs = validate_one_epoch(model, test, loss, show_test)\n","\n","  return out, rmse, y_fs"]},{"cell_type":"code","execution_count":null,"id":"d29c3c42-b52e-4cbb-8709-ad58192bd419","metadata":{"id":"d29c3c42-b52e-4cbb-8709-ad58192bd419"},"outputs":[],"source":["def TheVMD(tr, ts, colName, alpha, tau, K, tol, bch, n_step):\n","    u, u_hat, omega = VMD(tr[colName], alpha, tau, K, 0, 0, tol)\n","    ut, ut_hat = PostVMD(ts[colName], alpha, tau, K, 0, tol, omega[-1])\n","\n","    # Preparing Data\n","    Xs = tr.copy()\n","    Xts = ts.copy()\n","\n","    liXs = []\n","    liXts = []\n","\n","    for i in range(len(u)):\n","        Xs[colName] = u[i]\n","        Xts[colName] = ut[i]\n","        liXs.append(preparing(Xs, n_step, colName))\n","        liXts.append(preparing(Xts, n_step, colName))\n","\n","    for i in range(len(liXs)):\n","        liXs[i] = liXs[i].drop(index=liXs[i].index[:n_step])\n","        liXts[i] = liXts[i].drop(index=liXts[i].index[:n_step])\n","\n","    # Data Splitting\n","    ys = []\n","    yts = []\n","\n","    for a in range(len(liXs)):\n","        ys.append(liXs[a].pop(colName))\n","        yts.append(liXts[a].pop(colName))\n","\n","    # Shifting To Numpy\n","    liXs_np = []\n","    liXts_np = []\n","    ys_np = []\n","    yts_np = []\n","\n","    for i in range(len(liXs)):\n","        liXs_np.append(liXs[i].to_numpy())\n","        liXts_np.append(liXts[i].to_numpy())\n","        ys_np.append(ys[i].to_numpy())\n","        yts_np.append(yts[i].to_numpy())\n","\n","    # Flipping Train Columns For RNN-Based Algorithm\n","    for i in range(len(liXs)):\n","        liXs[i] = dc(np.flip(liXs_np[i], axis=1))\n","        liXts[i] = dc(np.flip(liXts_np[i], axis=1))\n","\n","    # Reshaping For Torch\n","    for i in range(len(liXs)):\n","        liXs_np[i] = liXs_np[i].reshape((-1, n_step, 1))\n","        liXts_np[i] = liXts_np[i].reshape((-1, n_step, 1))\n","        ys_np[i] = ys_np[i].reshape((-1, 1))\n","        yts_np[i] = yts_np[i].reshape((-1, 1))\n","\n","    # To TensorTorch\n","    for i in range(len(liXs)):\n","        liXs_np[i] = torch.tensor(liXs_np[i]).float()\n","        liXts_np[i] = torch.tensor(liXts_np[i]).float()\n","        ys_np[i] = torch.tensor(ys_np[i]).float()\n","        yts_np[i] = torch.tensor(yts_np[i]).float()\n","\n","    #print(\"Train Length \" ,len(liXs_np[0]))\n","    #print(\"Test Length \" ,len(liXts_np[0]))\n","\n","    Xs_cls = []\n","    Xts_cls = []\n","    for i in range(len(liXs_np)):\n","        Xs_cls.append(TimeData(liXs_np[i], ys_np[i]))\n","        Xts_cls.append(TimeData(liXts_np[i], yts_np[i]))\n","\n","    trn_load_vmd = []\n","    tst_load_vmd = []\n","\n","    for i in range(len(Xs_cls)):\n","        trn_load_vmd.append(DataLoader(Xs_cls[i], batch_size=bch, shuffle=True))\n","        tst_load_vmd.append(DataLoader(Xts_cls[i], batch_size=bch, shuffle=True))\n","\n","    return trn_load_vmd, tst_load_vmd"]},{"cell_type":"code","execution_count":null,"id":"e0b8319f-18f6-48e5-9f41-2dd0311545ac","metadata":{"id":"e0b8319f-18f6-48e5-9f41-2dd0311545ac"},"outputs":[],"source":["def PredictVMD(tr, ts, batches, n_step, colName):\n","    trnLSTM, tstLSTM = TheVMD(tr, ts, colName, 5000, 0, 30, 1e-5, batches, n_step)\n","    trnBLSTM, tstBLSTM = TheVMD(tr, ts, colName, 7000, 1, 20, 1e-7, batches, n_step)\n","    trnRNN, tstRNN = TheVMD(tr, ts, colName, 7000, 0, 30, 1e-5, batches, n_step)\n","    trnLin, tstLin = TheVMD(tr, ts, colName, 9000, 0, 10, 1e-7, batches, n_step)\n","    trnDLin, tstDLin = TheVMD(tr, ts, colName, 9000, 0, 30, 1e-5, batches, n_step)\n","    trnNLin, tstNLin = TheVMD(tr, ts, colName, 3000, 0, 20, 1e-7, batches, n_step)\n","\n","    li_lstm = []\n","    li_blstm = []\n","    li_rnn = []\n","    li_lin = []\n","    li_dlin = []\n","    li_nlin = []\n","\n","    # Define The Models\n","    for modi in range(len(trnLin)):\n","        lin = Lin(n_step, batches, 1, individual=True) # Dont Forget To Set Epoch = 30\n","        lin.to(device)\n","        li_lin.append(lin)\n","\n","    for magni in range(len(trnDLin)):\n","        dlin = DLin(n_step, batches, 1, individual=True) # Dont Forget To Set Epoch = 60\n","        dlin.to(device)\n","        li_dlin.append(dlin)\n","\n","        lstm = LSTM(1, 30, 1) # Dont Forget To Set Epoch = 70\n","        lstm.to(device)\n","        li_lstm.append(lstm)\n","\n","        rnn = SimpRNN(1, 40, 1) # Dont Forget To Set Epoch = 30\n","        rnn.to(device)\n","        li_rnn.append(rnn)\n","\n","    for lavender in range(len(trnNLin)):\n","        nlin = NLin(n_step, batches, 1, individual=True) # Dont Forget To Set Epoch = 70\n","        nlin.to(device)\n","        li_nlin.append(nlin)\n","\n","        blstm = BLSTM(1, 10, 1) # Dont Forget To Set Epoch = 30\n","        blstm.to(device)\n","        li_blstm.append(blstm)\n","\n","    # Start Predicting\n","    outLin = []\n","    y_fsmLin = []\n","    rmse_finLin = []\n","    rmseLin = 0\n","\n","    outDLin = []\n","    y_fsmDLin = []\n","    rmse_finDLin = []\n","    rmseDLin = 0\n","\n","    outNLin = []\n","    y_fsmNLin = []\n","    rmse_finNLin = []\n","    rmseNLin = 0\n","\n","    out = []\n","    y_fsm = []\n","    rmse_fin = []\n","    rmse = 0\n","\n","    outBLSTM = []\n","    y_fsmBLSTM = []\n","    rmse_finBLSTM = []\n","    rmseBLSTM = 0\n","\n","    outRNN = []\n","    y_fsmRNN = []\n","    rmse_finRNN = []\n","    rmseRNN = 0\n","\n","    for i in range(len(li_lstm)):\n","        tmp, rmse_tmp, y_f = train_test_v1(li_lstm[i], trnLSTM[i], tstLSTM[i], show_test=False, iterasi=70, linear=True)\n","        out.append(tmp)\n","        y_fsm.append(y_f)\n","        rmse_fin.append(rmse_tmp)\n","        rmse += rmse_tmp\n","\n","        tmp, rmse_tmp, y_f = train_test_v1(li_rnn[i], trnRNN[i], tstRNN[i], show_test=False, iterasi=30, linear=True)\n","        outRNN.append(tmp)\n","        y_fsmRNN.append(y_f)\n","        rmse_finRNN.append(rmse_tmp)\n","        rmseRNN += rmse_tmp\n","\n","        tmp, rmse_tmp, y_f = train_test_v1(li_dlin[i], trnDLin[i], tstDLin[i], show_test=False, iterasi=60, linear=True)\n","        outDLin.append(tmp)\n","        y_fsmDLin.append(y_f)\n","        rmse_finDLin.append(rmse_tmp)\n","        rmseDLin += rmse_tmp\n","\n","    for a in range(len(li_blstm)):\n","        tmp, rmse_tmp, y_f = train_test_v1(li_nlin[a], trnNLin[a], tstNLin[a], show_test=False, iterasi=70, linear=True)\n","        outNLin.append(tmp)\n","        y_fsmNLin.append(y_f)\n","        rmse_finNLin.append(rmse_tmp)\n","        rmseNLin += rmse_tmp\n","\n","        tmp, rmse_tmp, y_f = train_test_v1(li_blstm[a], trnBLSTM[a], tstBLSTM[a], show_test=False, iterasi=30, linear=True)\n","        outBLSTM.append(tmp)\n","        y_fsmBLSTM.append(y_f)\n","        rmse_finBLSTM.append(rmse_tmp)\n","        rmseBLSTM += rmse_tmp\n","\n","    for o in range(len(li_lin)):\n","        tmp, rmse_tmp, y_f = train_test_v1(li_lin[o], trnLin[o], tstLin[o], show_test=False, iterasi=30, linear=True)\n","        outLin.append(tmp)\n","        y_fsmLin.append(y_f)\n","        rmse_finLin.append(rmse_tmp)\n","        rmseLin += rmse_tmp\n","\n","    # Process The Result For RNN Based\n","    sumi = []\n","    y_forsum = []\n","    rmseLSTM = processResult(out, y_fsm, y_forsum, sumi)\n","\n","    sumBLSTM = []\n","    y_forsumBLSTM = []\n","    rmseBLSTM = processResult(outBLSTM, y_fsmBLSTM, y_forsumBLSTM, sumBLSTM)\n","\n","    sumRNN = []\n","    y_forsumRNN = []\n","    rmseRNN = processResult(outRNN, y_fsmRNN, y_forsumRNN, sumRNN)\n","\n","    # Process The Result For Linear Based\n","    sumLin = []\n","    y_forsumLin = []\n","    rmseLin = processResult(outLin, y_fsmLin, y_forsumLin, sumLin)\n","\n","    sumDLin = []\n","    y_forsumDLin = []\n","    rmseDLin = processResult(outDLin, y_fsmDLin, y_forsumDLin, sumDLin)\n","\n","    sumNLin = []\n","    y_forsumNLin = []\n","    rmseNLin = processResult(outNLin, y_fsmNLin, y_forsumNLin, sumNLin)\n","\n","    return [rmseLSTM, rmseBLSTM, rmseRNN, rmseLin, rmseDLin, rmseNLin]"]},{"cell_type":"code","source":["def processResultNoVMD(out, y_f, y_forsum, sums):\n","    '''for i, data in enumerate(out[0]):\n","        sums.append([])\n","        for a, dataA in enumerate(out):\n","            sums[i].append([])\n","\n","    for i, data in enumerate(y_f[0]):\n","        y_forsum.append([])\n","        for a, dataA in enumerate(y_f):\n","            y_forsum[i].append([])\n","\n","    #print(sum)\n","    for i, data in enumerate(out[0]):\n","        for a, dataA in enumerate(out):\n","            sums[i][a] = np.array(out[a][i].cpu())\n","        sums[i] = np.array(sums[i])\n","        sums[i] = sums[i].sum(axis=0)\n","\n","    for i, data in enumerate(y_f[0]):\n","        for a, dataA in enumerate(y_f):\n","            y_forsum[i][a] = y_f[a][i].tolist()\n","        #print(y_forsum[i])\n","        y_forsum[i] = np.array(y_forsum[i])\n","        y_forsum[i] = y_forsum[i].sum(axis=0)\n","\n","    for i, d in enumerate(sums):\n","        sums[i] = d.tolist()\n","        y_forsum[i] = y_forsum[i].tolist()\n","\n","    out1 = []\n","    y1 = []\n","    #print(len(sum))\n","    #print(len(y_fsm))\n","    for i, d in enumerate(sums[0]):\n","        for o, g in enumerate(sums[0][i]):\n","            out1.append(g)\n","            y1.append(y_forsum[i][o])\n","\n","    #print(sums, '\\n')\n","    #print(y_forsum, '\\n')\n","    #print(len(y1), '\\n', y1, '\\n\\n', len(out1), '\\n', out1)'''\n","    rmse_final = math.sqrt(mean_squared_error(y_f, out))\n","    return rmse_final\n","\n","def trainModelNoVMD(train, test, epoch, model):\n","  out = []\n","  y_fsm = []\n","  rmse_fin = []\n","  rmse = 0\n","\n","  tmp, rmse_tmp, y_f = train_test_v1(model, train, test, show_test=False, iterasi=epoch, linear=True)\n","  out.append(tmp)\n","  y_fsm.append(y_f)\n","  rmse_fin.append(rmse_tmp)\n","  rmse += rmse_tmp\n","\n","  sumi = []\n","  y_forsum = []\n","  rmse = processResultNoVMD(out, y_fsm, y_forsum, sumi)\n","\n","  return rmse"],"metadata":{"id":"24yy7aUXNLbY"},"id":"24yy7aUXNLbY","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def PredictNoVMD(tr, ts, batches, n_step, colName):\n","  lin = Lin(n_step, batches, 1, individual=True) # Dont Forget To Set Epoch = 30\n","  lin.to(device)\n","\n","  dlin = DLin(n_step, batches, 1, individual=True) # Dont Forget To Set Epoch = 60\n","  dlin.to(device)\n","\n","  nlin = NLin(n_step, batches, 1, individual=True) # Dont Forget To Set Epoch = 70\n","  nlin.to(device)\n","\n","  lstm = LSTM(1, 30, 1) # Dont Forget To Set Epoch = 70\n","  lstm.to(device)\n","\n","  blstm = BLSTM(1, 10, 1) # Dont Forget To Set Epoch = 30\n","  blstm.to(device)\n","\n","  rnn = SimpRNN(1, 40, 1) # Dont Forget To Set Epoch = 30\n","  rnn.to(device)\n","\n","  rmseLin = trainModelNoVMD(tr, ts, 30, lin)\n","  rmseDLin = trainModelNoVMD(tr, ts, 60, dlin)\n","  rmseNLin = trainModelNoVMD(tr, ts, 70, nlin)\n","\n","  rmseLSTM = trainModelNoVMD(tr, ts, 70, lstm)\n","  rmseBLSTM = trainModelNoVMD(tr, ts, 30, blstm)\n","  rmseRNN = trainModelNoVMD(tr, ts, 30, rnn)"],"metadata":{"id":"YnL0z-JSK7M7"},"id":"YnL0z-JSK7M7","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"34f227e2-2fd2-4f9f-9b21-adb68e43275d","metadata":{"id":"34f227e2-2fd2-4f9f-9b21-adb68e43275d"},"outputs":[],"source":["rmseModel = []\n","\n","for idx, data in enumerate(trn_li):\n","    col = list(data.columns.values)[-1]\n","    trn_li[idx] = pd.DataFrame(trn_li[idx][col])\n","    tst_li[idx] = pd.DataFrame(tst_li[idx][col])\n","\n","    tmpModel = PredictVMD(trn_li[idx], tst_li[idx], 6, 6, col)\n","    print(tmpModel)\n","    rmseModel.append(tmpModel)\n","\n","with open(\"/content/gdrive/My Drive/Skripsi VMD LSTM Udara/Progress/Result/resultUniVMD.pkl\", 'wb') as f:\n","    pickle.dump(rmseModel, f)\n","    print(\"File Successfully Created\")"]},{"cell_type":"code","source":["rmseModelNoVMD = []\n","\n","for idx, data in enumerate(trn_li):\n","    col = list(data.columns.values)[-1]\n","    trn_li[idx] = pd.DataFrame(trn_li[idx][col])\n","    tst_li[idx] = pd.DataFrame(tst_li[idx][col])\n","\n","    tmpModel = PredictNoVMD(trn_li[idx], tst_li[idx], 6, 6, col)\n","    print(tmpModel)\n","    rmseModelNoVMD.append(tmpModel)\n","\n","with open(\"/content/gdrive/My Drive/Skripsi VMD LSTM Udara/Progress/Result/resultUni.pkl\", 'wb') as f:\n","    pickle.dump(rmseModelNoVMD, f)\n","    print(\"File Successfully Created\")"],"metadata":{"id":"fXyYyhwIPj2Y"},"id":"fXyYyhwIPj2Y","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"V28"},"kernelspec":{"display_name":"VMDEnv","language":"python","name":"vmdenv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":5}
